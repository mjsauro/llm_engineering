{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "Synthetic Data Set Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install openai gradio python-dotenv jupyter-black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import gradio as gr\n",
    "from typing import List, Dict\n",
    "import random\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client pointing to OpenRouter\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    ")\n",
    "\n",
    "ollama_client = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",  # Ollama's local endpoint\n",
    "    api_key=\"ollama\",  # Ollama doesn't need a real API key, but the SDK requires something\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the connection with a simple call\n",
    "response = client.chat.completions.create(\n",
    "    model=\"anthropic/claude-3.5-sonnet\",  # You can change this to other models\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say 'Hello! Connection successful!' if you can read this.\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_support_conversation(\n",
    "    domain: str,\n",
    "    issue_type: str,\n",
    "    conversation_length: str,\n",
    "    tone: str,\n",
    "    model: str = \"anthropic/claude-3.5-sonnet\",\n",
    "    use_ollama: bool = False,\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Generate a synthetic customer support conversation.\n",
    "\n",
    "    Args:\n",
    "        domain: Business domain (e-commerce, SaaS, banking, etc.)\n",
    "        issue_type: Type of customer issue\n",
    "        conversation_length: short, medium, or long\n",
    "        tone: friendly, professional, frustrated, etc.\n",
    "        model: The model to use\n",
    "        use_ollama: Whether to use local Ollama instead of OpenRouter\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing the conversation and metadata\n",
    "    \"\"\"\n",
    "\n",
    "    # Map conversation length to number of exchanges\n",
    "    length_map = {\"short\": \"3-4\", \"medium\": \"5-7\", \"long\": \"8-12\"}\n",
    "\n",
    "    num_exchanges = length_map.get(conversation_length, \"5-7\")\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = f\"\"\"Generate a realistic customer support conversation for a {domain} company.\n",
    "\n",
    "Issue Type: {issue_type}\n",
    "Customer Tone: {tone}\n",
    "Number of message exchanges: {num_exchanges} (customer and agent messages combined)\n",
    "\n",
    "Requirements:\n",
    "- Make it realistic with natural language, including minor typos or informal language from the customer\n",
    "- The agent should be helpful and professional\n",
    "- Include a resolution or clear next steps\n",
    "- Format as JSON with this structure:\n",
    "{{\n",
    "    \"conversation\": [\n",
    "        {{\"speaker\": \"customer\", \"message\": \"...\"}},\n",
    "        {{\"speaker\": \"agent\", \"message\": \"...\"}}\n",
    "    ],\n",
    "    \"metadata\": {{\n",
    "        \"issue_category\": \"...\",\n",
    "        \"resolution_status\": \"resolved/pending/escalated\",\n",
    "        \"customer_satisfaction\": \"positive/neutral/negative\"\n",
    "    }}\n",
    "}}\n",
    "\n",
    "Generate only the JSON, no other text.\"\"\"\n",
    "\n",
    "    try:\n",
    "        # Choose which client to use\n",
    "        active_client = ollama_client if use_ollama else client\n",
    "\n",
    "        response = active_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.8,\n",
    "        )\n",
    "\n",
    "        # Parse the response\n",
    "        content = response.choices[0].message.content\n",
    "\n",
    "        # Clean up potential markdown formatting\n",
    "        if \"```json\" in content:\n",
    "            content = content.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"```\" in content:\n",
    "            content = content.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "        conversation_data = json.loads(content)\n",
    "        return conversation_data\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"conversation\": [], \"metadata\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_conversation_for_display(conversation_data: Dict) -> tuple:\n",
    "    \"\"\"\n",
    "    Format the conversation data for Gradio display.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (chatbot_messages, metadata_text, json_output)\n",
    "    \"\"\"\n",
    "    if \"error\" in conversation_data:\n",
    "        return (\n",
    "            [],\n",
    "            f\"Error: {conversation_data['error']}\",\n",
    "            json.dumps(conversation_data, indent=2),\n",
    "        )\n",
    "\n",
    "    # Format for Gradio Chatbot component (list of [user_msg, bot_msg] pairs)\n",
    "    chatbot_messages = []\n",
    "    conversation = conversation_data.get(\"conversation\", [])\n",
    "\n",
    "    # Pair up customer and agent messages\n",
    "    i = 0\n",
    "    while i < len(conversation):\n",
    "        customer_msg = None\n",
    "        agent_msg = None\n",
    "\n",
    "        if i < len(conversation) and conversation[i][\"speaker\"] == \"customer\":\n",
    "            customer_msg = conversation[i][\"message\"]\n",
    "            i += 1\n",
    "\n",
    "        if i < len(conversation) and conversation[i][\"speaker\"] == \"agent\":\n",
    "            agent_msg = conversation[i][\"message\"]\n",
    "            i += 1\n",
    "\n",
    "        chatbot_messages.append([customer_msg, agent_msg])\n",
    "\n",
    "    # Format metadata\n",
    "    metadata = conversation_data.get(\"metadata\", {})\n",
    "    metadata_text = f\"\"\"**Metadata:**\n",
    "- Issue Category: {metadata.get('issue_category', 'N/A')}\n",
    "- Resolution Status: {metadata.get('resolution_status', 'N/A')}\n",
    "- Customer Satisfaction: {metadata.get('customer_satisfaction', 'N/A')}\n",
    "\"\"\"\n",
    "\n",
    "    # JSON output\n",
    "    json_output = json.dumps(conversation_data, indent=2)\n",
    "\n",
    "    return chatbot_messages, metadata_text, json_output\n",
    "\n",
    "\n",
    "def generate_conversation_ui(domain, issue_type, length, tone, model):\n",
    "    \"\"\"Wrapper function for Gradio interface\"\"\"\n",
    "    conversation_data = generate_support_conversation(\n",
    "        domain=domain,\n",
    "        issue_type=issue_type,\n",
    "        conversation_length=length,\n",
    "        tone=tone,\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    return format_conversation_for_display(conversation_data)\n",
    "\n",
    "\n",
    "# Create the Gradio interface\n",
    "with gr.Blocks(title=\"Customer Support Conversation Generator\") as demo:\n",
    "    gr.Markdown(\"# ðŸŽ­ Synthetic Customer Support Conversation Generator\")\n",
    "    gr.Markdown(\n",
    "        \"Generate realistic customer support conversations for training, testing, or demonstrations.\"\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"### Configuration\")\n",
    "\n",
    "            domain = gr.Dropdown(\n",
    "                choices=[\n",
    "                    \"E-commerce\",\n",
    "                    \"SaaS\",\n",
    "                    \"Banking\",\n",
    "                    \"Telecommunications\",\n",
    "                    \"Healthcare\",\n",
    "                    \"Travel\",\n",
    "                ],\n",
    "                value=\"E-commerce\",\n",
    "                label=\"Business Domain\",\n",
    "            )\n",
    "\n",
    "            issue_type = gr.Dropdown(\n",
    "                choices=[\n",
    "                    \"Refund Request\",\n",
    "                    \"Technical Problem\",\n",
    "                    \"Account Access\",\n",
    "                    \"Billing Question\",\n",
    "                    \"Product Inquiry\",\n",
    "                    \"Shipping Issue\",\n",
    "                    \"Feature Request\",\n",
    "                    \"Complaint\",\n",
    "                ],\n",
    "                value=\"Refund Request\",\n",
    "                label=\"Issue Type\",\n",
    "            )\n",
    "\n",
    "            length = gr.Radio(\n",
    "                choices=[\"short\", \"medium\", \"long\"],\n",
    "                value=\"medium\",\n",
    "                label=\"Conversation Length\",\n",
    "            )\n",
    "\n",
    "            tone = gr.Dropdown(\n",
    "                choices=[\n",
    "                    \"Friendly\",\n",
    "                    \"Professional\",\n",
    "                    \"Frustrated\",\n",
    "                    \"Confused\",\n",
    "                    \"Urgent\",\n",
    "                ],\n",
    "                value=\"Friendly\",\n",
    "                label=\"Customer Tone\",\n",
    "            )\n",
    "\n",
    "            model = gr.Dropdown(\n",
    "                choices=[\n",
    "                    \"anthropic/claude-3.5-sonnet\",\n",
    "                    \"openai/gpt-4o\",\n",
    "                    \"google/gemini-pro\",\n",
    "                    \"meta-llama/llama-3.1-70b-instruct\",\n",
    "                ],\n",
    "                value=\"anthropic/claude-3.5-sonnet\",\n",
    "                label=\"Model\",\n",
    "            )\n",
    "\n",
    "            generate_btn = gr.Button(\"Generate Conversation\", variant=\"primary\")\n",
    "\n",
    "        with gr.Column(scale=2):\n",
    "            gr.Markdown(\"### Generated Conversation\")\n",
    "            chatbot = gr.Chatbot(label=\"Conversation\", height=400)\n",
    "            metadata_display = gr.Markdown(\"*Generate a conversation to see metadata*\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"### JSON Output\")\n",
    "            json_output = gr.Code(label=\"Raw JSON\", language=\"json\", lines=15)\n",
    "\n",
    "    # Connect the generate button\n",
    "    generate_btn.click(\n",
    "        fn=generate_conversation_ui,\n",
    "        inputs=[domain, issue_type, length, tone, model],\n",
    "        outputs=[chatbot, metadata_display, json_output],\n",
    "    )\n",
    "\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "    ### Tips:\n",
    "    - Try different models to compare output quality and style\n",
    "    - Experiment with different tones to see how it affects the conversation\n",
    "    - Use the JSON output to integrate into your applications\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "# Launch the interface\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def generate_batch_conversations(\n",
    "    domain: str,\n",
    "    issue_type: str,\n",
    "    length: str,\n",
    "    tone: str,\n",
    "    model: str,\n",
    "    num_conversations: int,\n",
    ") -> tuple:\n",
    "    \"\"\"Generate multiple conversations at once\"\"\"\n",
    "\n",
    "    all_conversations = []\n",
    "    progress_updates = []\n",
    "\n",
    "    for i in range(num_conversations):\n",
    "        progress_updates.append(f\"Generating conversation {i+1}/{num_conversations}...\")\n",
    "\n",
    "        conversation_data = generate_support_conversation(\n",
    "            domain=domain,\n",
    "            issue_type=issue_type,\n",
    "            conversation_length=length,\n",
    "            tone=tone,\n",
    "            model=model,\n",
    "        )\n",
    "\n",
    "        # Add an ID and timestamp\n",
    "        conversation_data[\"id\"] = (\n",
    "            f\"conv_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{i+1}\"\n",
    "        )\n",
    "        conversation_data[\"generated_at\"] = datetime.now().isoformat()\n",
    "        conversation_data[\"config\"] = {\n",
    "            \"domain\": domain,\n",
    "            \"issue_type\": issue_type,\n",
    "            \"length\": length,\n",
    "            \"tone\": tone,\n",
    "            \"model\": model,\n",
    "        }\n",
    "\n",
    "        all_conversations.append(conversation_data)\n",
    "\n",
    "    # Create a summary\n",
    "    summary = f\"\"\"### Batch Generation Complete!\n",
    "    \n",
    "**Generated:** {num_conversations} conversations\n",
    "**Domain:** {domain}\n",
    "**Issue Type:** {issue_type}\n",
    "**Model:** {model}\n",
    "\n",
    "You can now download the results as JSON or CSV.\n",
    "\"\"\"\n",
    "\n",
    "    # Convert to JSON string for download\n",
    "    json_str = json.dumps(all_conversations, indent=2)\n",
    "\n",
    "    # Create CSV format (flattened data)\n",
    "    csv_data = []\n",
    "    for conv in all_conversations:\n",
    "        # Flatten conversation into a single row\n",
    "        messages = conv.get(\"conversation\", [])\n",
    "        full_conversation = \"\\n\".join(\n",
    "            [f\"{msg['speaker']}: {msg['message']}\" for msg in messages]\n",
    "        )\n",
    "\n",
    "        csv_data.append(\n",
    "            {\n",
    "                \"id\": conv.get(\"id\"),\n",
    "                \"domain\": domain,\n",
    "                \"issue_type\": issue_type,\n",
    "                \"tone\": tone,\n",
    "                \"conversation\": full_conversation,\n",
    "                \"issue_category\": conv.get(\"metadata\", {}).get(\"issue_category\"),\n",
    "                \"resolution_status\": conv.get(\"metadata\", {}).get(\"resolution_status\"),\n",
    "                \"customer_satisfaction\": conv.get(\"metadata\", {}).get(\n",
    "                    \"customer_satisfaction\"\n",
    "                ),\n",
    "                \"generated_at\": conv.get(\"generated_at\"),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(csv_data)\n",
    "    csv_str = df.to_csv(index=False)\n",
    "\n",
    "    return summary, json_str, csv_str\n",
    "\n",
    "\n",
    "# Enhanced Gradio interface with batch generation\n",
    "with gr.Blocks(\n",
    "    title=\"Customer Support Conversation Generator\", theme=gr.themes.Soft()\n",
    ") as demo:\n",
    "    gr.Markdown(\"# ðŸŽ­ Synthetic Customer Support Conversation Generator\")\n",
    "    gr.Markdown(\n",
    "        \"Generate realistic customer support conversations for training, testing, or demonstrations.\"\n",
    "    )\n",
    "\n",
    "    with gr.Tabs():\n",
    "        # Tab 1: Single Generation\n",
    "        with gr.Tab(\"Single Conversation\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    gr.Markdown(\"### Configuration\")\n",
    "\n",
    "                    domain_single = gr.Dropdown(\n",
    "                        choices=[\n",
    "                            \"E-commerce\",\n",
    "                            \"SaaS\",\n",
    "                            \"Banking\",\n",
    "                            \"Telecommunications\",\n",
    "                            \"Healthcare\",\n",
    "                            \"Travel\",\n",
    "                        ],\n",
    "                        value=\"E-commerce\",\n",
    "                        label=\"Business Domain\",\n",
    "                    )\n",
    "\n",
    "                    issue_type_single = gr.Dropdown(\n",
    "                        choices=[\n",
    "                            \"Refund Request\",\n",
    "                            \"Technical Problem\",\n",
    "                            \"Account Access\",\n",
    "                            \"Billing Question\",\n",
    "                            \"Product Inquiry\",\n",
    "                            \"Shipping Issue\",\n",
    "                            \"Feature Request\",\n",
    "                            \"Complaint\",\n",
    "                        ],\n",
    "                        value=\"Refund Request\",\n",
    "                        label=\"Issue Type\",\n",
    "                    )\n",
    "\n",
    "                    length_single = gr.Radio(\n",
    "                        choices=[\"short\", \"medium\", \"long\"],\n",
    "                        value=\"medium\",\n",
    "                        label=\"Conversation Length\",\n",
    "                    )\n",
    "\n",
    "                    tone_single = gr.Dropdown(\n",
    "                        choices=[\n",
    "                            \"Friendly\",\n",
    "                            \"Professional\",\n",
    "                            \"Frustrated\",\n",
    "                            \"Confused\",\n",
    "                            \"Urgent\",\n",
    "                        ],\n",
    "                        value=\"Friendly\",\n",
    "                        label=\"Customer Tone\",\n",
    "                    )\n",
    "\n",
    "                    model_single = gr.Dropdown(\n",
    "                        choices=[\n",
    "                            \"anthropic/claude-3.5-sonnet\",\n",
    "                            \"openai/gpt-4o\",\n",
    "                            \"google/gemini-pro\",\n",
    "                            \"meta-llama/llama-3.1-70b-instruct\",\n",
    "                        ],\n",
    "                        value=\"anthropic/claude-3.5-sonnet\",\n",
    "                        label=\"Model\",\n",
    "                    )\n",
    "\n",
    "                    generate_btn_single = gr.Button(\n",
    "                        \"Generate Conversation\", variant=\"primary\"\n",
    "                    )\n",
    "\n",
    "                with gr.Column(scale=2):\n",
    "                    gr.Markdown(\"### Generated Conversation\")\n",
    "                    chatbot_single = gr.Chatbot(label=\"Conversation\", height=400)\n",
    "                    metadata_display_single = gr.Markdown(\n",
    "                        \"*Generate a conversation to see metadata*\"\n",
    "                    )\n",
    "\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    gr.Markdown(\"### JSON Output\")\n",
    "                    json_output_single = gr.Code(\n",
    "                        label=\"Raw JSON\", language=\"json\", lines=15\n",
    "                    )\n",
    "\n",
    "            generate_btn_single.click(\n",
    "                fn=generate_conversation_ui,\n",
    "                inputs=[\n",
    "                    domain_single,\n",
    "                    issue_type_single,\n",
    "                    length_single,\n",
    "                    tone_single,\n",
    "                    model_single,\n",
    "                ],\n",
    "                outputs=[chatbot_single, metadata_display_single, json_output_single],\n",
    "            )\n",
    "\n",
    "        # Tab 2: Batch Generation\n",
    "        with gr.Tab(\"Batch Generation\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    gr.Markdown(\"### Batch Configuration\")\n",
    "\n",
    "                    num_conversations = gr.Slider(\n",
    "                        minimum=2,\n",
    "                        maximum=20,\n",
    "                        value=5,\n",
    "                        step=1,\n",
    "                        label=\"Number of Conversations\",\n",
    "                    )\n",
    "\n",
    "                    domain_batch = gr.Dropdown(\n",
    "                        choices=[\n",
    "                            \"E-commerce\",\n",
    "                            \"SaaS\",\n",
    "                            \"Banking\",\n",
    "                            \"Telecommunications\",\n",
    "                            \"Healthcare\",\n",
    "                            \"Travel\",\n",
    "                        ],\n",
    "                        value=\"E-commerce\",\n",
    "                        label=\"Business Domain\",\n",
    "                    )\n",
    "\n",
    "                    issue_type_batch = gr.Dropdown(\n",
    "                        choices=[\n",
    "                            \"Refund Request\",\n",
    "                            \"Technical Problem\",\n",
    "                            \"Account Access\",\n",
    "                            \"Billing Question\",\n",
    "                            \"Product Inquiry\",\n",
    "                            \"Shipping Issue\",\n",
    "                            \"Feature Request\",\n",
    "                            \"Complaint\",\n",
    "                        ],\n",
    "                        value=\"Refund Request\",\n",
    "                        label=\"Issue Type\",\n",
    "                    )\n",
    "\n",
    "                    length_batch = gr.Radio(\n",
    "                        choices=[\"short\", \"medium\", \"long\"],\n",
    "                        value=\"medium\",\n",
    "                        label=\"Conversation Length\",\n",
    "                    )\n",
    "\n",
    "                    tone_batch = gr.Dropdown(\n",
    "                        choices=[\n",
    "                            \"Friendly\",\n",
    "                            \"Professional\",\n",
    "                            \"Frustrated\",\n",
    "                            \"Confused\",\n",
    "                            \"Urgent\",\n",
    "                        ],\n",
    "                        value=\"Friendly\",\n",
    "                        label=\"Customer Tone\",\n",
    "                    )\n",
    "\n",
    "                    model_batch = gr.Dropdown(\n",
    "                        choices=[\n",
    "                            \"anthropic/claude-3.5-sonnet\",\n",
    "                            \"openai/gpt-4o\",\n",
    "                            \"google/gemini-pro\",\n",
    "                            \"meta-llama/llama-3.1-70b-instruct\",\n",
    "                        ],\n",
    "                        value=\"anthropic/claude-3.5-sonnet\",\n",
    "                        label=\"Model\",\n",
    "                    )\n",
    "\n",
    "                    generate_btn_batch = gr.Button(\n",
    "                        \"Generate Batch\", variant=\"primary\", size=\"lg\"\n",
    "                    )\n",
    "\n",
    "                with gr.Column(scale=2):\n",
    "                    summary_output = gr.Markdown(\n",
    "                        \"*Configure and generate a batch of conversations*\"\n",
    "                    )\n",
    "\n",
    "                    with gr.Row():\n",
    "                        json_download = gr.File(label=\"Download JSON\")\n",
    "                        csv_download = gr.File(label=\"Download CSV\")\n",
    "\n",
    "            def generate_and_save_batch(domain, issue_type, length, tone, model, num):\n",
    "                summary, json_str, csv_str = generate_batch_conversations(\n",
    "                    domain, issue_type, length, tone, model, num\n",
    "                )\n",
    "\n",
    "                # Save to temporary files\n",
    "                json_filename = (\n",
    "                    f\"conversations_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "                )\n",
    "                csv_filename = (\n",
    "                    f\"conversations_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "                )\n",
    "\n",
    "                with open(json_filename, \"w\") as f:\n",
    "                    f.write(json_str)\n",
    "\n",
    "                with open(csv_filename, \"w\") as f:\n",
    "                    f.write(csv_str)\n",
    "\n",
    "                return summary, json_filename, csv_filename\n",
    "\n",
    "            generate_btn_batch.click(\n",
    "                fn=generate_and_save_batch,\n",
    "                inputs=[\n",
    "                    domain_batch,\n",
    "                    issue_type_batch,\n",
    "                    length_batch,\n",
    "                    tone_batch,\n",
    "                    model_batch,\n",
    "                    num_conversations,\n",
    "                ],\n",
    "                outputs=[summary_output, json_download, csv_download],\n",
    "            )\n",
    "\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "    ### Tips:\n",
    "    - **Single Conversation:** Perfect for testing and seeing immediate results\n",
    "    - **Batch Generation:** Generate multiple conversations at once for training datasets\n",
    "    - Try different models to compare output quality and style\n",
    "    - Export to JSON for application integration or CSV for analysis\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "# Launch the enhanced interface\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_conversation_ui(domain, issue_type, length, tone, model, provider):\n",
    "    \"\"\"Wrapper function for Gradio interface\"\"\"\n",
    "    use_ollama = provider == \"Ollama (Local)\"\n",
    "\n",
    "    conversation_data = generate_support_conversation(\n",
    "        domain=domain,\n",
    "        issue_type=issue_type,\n",
    "        conversation_length=length,\n",
    "        tone=tone,\n",
    "        model=model,\n",
    "        use_ollama=use_ollama,\n",
    "    )\n",
    "\n",
    "    return format_conversation_for_display(conversation_data)\n",
    "\n",
    "\n",
    "def generate_batch_conversations(\n",
    "    domain: str,\n",
    "    issue_type: str,\n",
    "    length: str,\n",
    "    tone: str,\n",
    "    model: str,\n",
    "    num_conversations: int,\n",
    "    provider: str,\n",
    ") -> tuple:\n",
    "    \"\"\"Generate multiple conversations at once\"\"\"\n",
    "\n",
    "    use_ollama = provider == \"Ollama (Local)\"\n",
    "    all_conversations = []\n",
    "\n",
    "    for i in range(num_conversations):\n",
    "        conversation_data = generate_support_conversation(\n",
    "            domain=domain,\n",
    "            issue_type=issue_type,\n",
    "            conversation_length=length,\n",
    "            tone=tone,\n",
    "            model=model,\n",
    "            use_ollama=use_ollama,\n",
    "        )\n",
    "\n",
    "        # Add an ID and timestamp\n",
    "        conversation_data[\"id\"] = (\n",
    "            f\"conv_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{i+1}\"\n",
    "        )\n",
    "        conversation_data[\"generated_at\"] = datetime.now().isoformat()\n",
    "        conversation_data[\"config\"] = {\n",
    "            \"domain\": domain,\n",
    "            \"issue_type\": issue_type,\n",
    "            \"length\": length,\n",
    "            \"tone\": tone,\n",
    "            \"model\": model,\n",
    "            \"provider\": provider,\n",
    "        }\n",
    "\n",
    "        all_conversations.append(conversation_data)\n",
    "\n",
    "    # Create a summary\n",
    "    summary = f\"\"\"### Batch Generation Complete!\n",
    "    \n",
    "**Generated:** {num_conversations} conversations\n",
    "**Provider:** {provider}\n",
    "**Domain:** {domain}\n",
    "**Issue Type:** {issue_type}\n",
    "**Model:** {model}\n",
    "\n",
    "You can now download the results as JSON or CSV.\n",
    "\"\"\"\n",
    "\n",
    "    # Convert to JSON string for download\n",
    "    json_str = json.dumps(all_conversations, indent=2)\n",
    "\n",
    "    # Create CSV format (flattened data)\n",
    "    csv_data = []\n",
    "    for conv in all_conversations:\n",
    "        messages = conv.get(\"conversation\", [])\n",
    "        full_conversation = \"\\n\".join(\n",
    "            [f\"{msg['speaker']}: {msg['message']}\" for msg in messages]\n",
    "        )\n",
    "\n",
    "        csv_data.append(\n",
    "            {\n",
    "                \"id\": conv.get(\"id\"),\n",
    "                \"domain\": domain,\n",
    "                \"issue_type\": issue_type,\n",
    "                \"tone\": tone,\n",
    "                \"conversation\": full_conversation,\n",
    "                \"issue_category\": conv.get(\"metadata\", {}).get(\"issue_category\"),\n",
    "                \"resolution_status\": conv.get(\"metadata\", {}).get(\"resolution_status\"),\n",
    "                \"customer_satisfaction\": conv.get(\"metadata\", {}).get(\n",
    "                    \"customer_satisfaction\"\n",
    "                ),\n",
    "                \"generated_at\": conv.get(\"generated_at\"),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(csv_data)\n",
    "    csv_str = df.to_csv(index=False)\n",
    "\n",
    "    return summary, json_str, csv_str\n",
    "\n",
    "\n",
    "# Enhanced Gradio interface with Ollama support\n",
    "with gr.Blocks(\n",
    "    title=\"Customer Support Conversation Generator\", theme=gr.themes.Soft()\n",
    ") as demo:\n",
    "    gr.Markdown(\"# ðŸŽ­ Synthetic Customer Support Conversation Generator\")\n",
    "    gr.Markdown(\n",
    "        \"Generate realistic customer support conversations using OpenRouter or local Ollama models.\"\n",
    "    )\n",
    "\n",
    "    with gr.Tabs():\n",
    "        # Tab 1: Single Generation\n",
    "        with gr.Tab(\"Single Conversation\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    gr.Markdown(\"### Configuration\")\n",
    "\n",
    "                    provider_single = gr.Radio(\n",
    "                        choices=[\"OpenRouter (Cloud)\", \"Ollama (Local)\"],\n",
    "                        value=\"OpenRouter (Cloud)\",\n",
    "                        label=\"Provider\",\n",
    "                    )\n",
    "\n",
    "                    model_single = gr.Dropdown(\n",
    "                        choices=[\n",
    "                            \"anthropic/claude-3.5-sonnet\",\n",
    "                            \"openai/gpt-4o\",\n",
    "                            \"google/gemini-pro\",\n",
    "                            \"meta-llama/llama-3.1-70b-instruct\",\n",
    "                        ],\n",
    "                        value=\"anthropic/claude-3.5-sonnet\",\n",
    "                        label=\"Model (OpenRouter)\",\n",
    "                    )\n",
    "\n",
    "                    ollama_model_single = gr.Textbox(\n",
    "                        value=\"llama3.1\",\n",
    "                        label=\"Model (Ollama)\",\n",
    "                        placeholder=\"e.g., llama3.1, mistral, qwen2.5\",\n",
    "                    )\n",
    "\n",
    "                    domain_single = gr.Dropdown(\n",
    "                        choices=[\n",
    "                            \"E-commerce\",\n",
    "                            \"SaaS\",\n",
    "                            \"Banking\",\n",
    "                            \"Telecommunications\",\n",
    "                            \"Healthcare\",\n",
    "                            \"Travel\",\n",
    "                        ],\n",
    "                        value=\"E-commerce\",\n",
    "                        label=\"Business Domain\",\n",
    "                    )\n",
    "\n",
    "                    issue_type_single = gr.Dropdown(\n",
    "                        choices=[\n",
    "                            \"Refund Request\",\n",
    "                            \"Technical Problem\",\n",
    "                            \"Account Access\",\n",
    "                            \"Billing Question\",\n",
    "                            \"Product Inquiry\",\n",
    "                            \"Shipping Issue\",\n",
    "                            \"Feature Request\",\n",
    "                            \"Complaint\",\n",
    "                        ],\n",
    "                        value=\"Refund Request\",\n",
    "                        label=\"Issue Type\",\n",
    "                    )\n",
    "\n",
    "                    length_single = gr.Radio(\n",
    "                        choices=[\"short\", \"medium\", \"long\"],\n",
    "                        value=\"medium\",\n",
    "                        label=\"Conversation Length\",\n",
    "                    )\n",
    "\n",
    "                    tone_single = gr.Dropdown(\n",
    "                        choices=[\n",
    "                            \"Friendly\",\n",
    "                            \"Professional\",\n",
    "                            \"Frustrated\",\n",
    "                            \"Confused\",\n",
    "                            \"Urgent\",\n",
    "                        ],\n",
    "                        value=\"Friendly\",\n",
    "                        label=\"Customer Tone\",\n",
    "                    )\n",
    "\n",
    "                    generate_btn_single = gr.Button(\n",
    "                        \"Generate Conversation\", variant=\"primary\"\n",
    "                    )\n",
    "\n",
    "                with gr.Column(scale=2):\n",
    "                    gr.Markdown(\"### Generated Conversation\")\n",
    "                    chatbot_single = gr.Chatbot(label=\"Conversation\", height=400)\n",
    "                    metadata_display_single = gr.Markdown(\n",
    "                        \"*Generate a conversation to see metadata*\"\n",
    "                    )\n",
    "\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    gr.Markdown(\"### JSON Output\")\n",
    "                    json_output_single = gr.Code(\n",
    "                        label=\"Raw JSON\", language=\"json\", lines=15\n",
    "                    )\n",
    "\n",
    "            def generate_with_provider_single(\n",
    "                domain, issue_type, length, tone, model, ollama_model, provider\n",
    "            ):\n",
    "                selected_model = ollama_model if provider == \"Ollama (Local)\" else model\n",
    "                return generate_conversation_ui(\n",
    "                    domain, issue_type, length, tone, selected_model, provider\n",
    "                )\n",
    "\n",
    "            generate_btn_single.click(\n",
    "                fn=generate_with_provider_single,\n",
    "                inputs=[\n",
    "                    domain_single,\n",
    "                    issue_type_single,\n",
    "                    length_single,\n",
    "                    tone_single,\n",
    "                    model_single,\n",
    "                    ollama_model_single,\n",
    "                    provider_single,\n",
    "                ],\n",
    "                outputs=[chatbot_single, metadata_display_single, json_output_single],\n",
    "            )\n",
    "\n",
    "        # Tab 2: Batch Generation\n",
    "        with gr.Tab(\"Batch Generation\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    gr.Markdown(\"### Batch Configuration\")\n",
    "\n",
    "                    num_conversations = gr.Slider(\n",
    "                        minimum=2,\n",
    "                        maximum=20,\n",
    "                        value=5,\n",
    "                        step=1,\n",
    "                        label=\"Number of Conversations\",\n",
    "                    )\n",
    "\n",
    "                    provider_batch = gr.Radio(\n",
    "                        choices=[\"OpenRouter (Cloud)\", \"Ollama (Local)\"],\n",
    "                        value=\"OpenRouter (Cloud)\",\n",
    "                        label=\"Provider\",\n",
    "                    )\n",
    "\n",
    "                    model_batch = gr.Dropdown(\n",
    "                        choices=[\n",
    "                            \"anthropic/claude-3.5-sonnet\",\n",
    "                            \"openai/gpt-4o\",\n",
    "                            \"google/gemini-pro\",\n",
    "                            \"meta-llama/llama-3.1-70b-instruct\",\n",
    "                        ],\n",
    "                        value=\"anthropic/claude-3.5-sonnet\",\n",
    "                        label=\"Model (OpenRouter)\",\n",
    "                    )\n",
    "\n",
    "                    ollama_model_batch = gr.Textbox(\n",
    "                        value=\"llama3.1\",\n",
    "                        label=\"Model (Ollama)\",\n",
    "                        placeholder=\"e.g., llama3.1, mistral, qwen2.5\",\n",
    "                    )\n",
    "\n",
    "                    domain_batch = gr.Dropdown(\n",
    "                        choices=[\n",
    "                            \"E-commerce\",\n",
    "                            \"SaaS\",\n",
    "                            \"Banking\",\n",
    "                            \"Telecommunications\",\n",
    "                            \"Healthcare\",\n",
    "                            \"Travel\",\n",
    "                        ],\n",
    "                        value=\"E-commerce\",\n",
    "                        label=\"Business Domain\",\n",
    "                    )\n",
    "\n",
    "                    issue_type_batch = gr.Dropdown(\n",
    "                        choices=[\n",
    "                            \"Refund Request\",\n",
    "                            \"Technical Problem\",\n",
    "                            \"Account Access\",\n",
    "                            \"Billing Question\",\n",
    "                            \"Product Inquiry\",\n",
    "                            \"Shipping Issue\",\n",
    "                            \"Feature Request\",\n",
    "                            \"Complaint\",\n",
    "                        ],\n",
    "                        value=\"Refund Request\",\n",
    "                        label=\"Issue Type\",\n",
    "                    )\n",
    "\n",
    "                    length_batch = gr.Radio(\n",
    "                        choices=[\"short\", \"medium\", \"long\"],\n",
    "                        value=\"medium\",\n",
    "                        label=\"Conversation Length\",\n",
    "                    )\n",
    "\n",
    "                    tone_batch = gr.Dropdown(\n",
    "                        choices=[\n",
    "                            \"Friendly\",\n",
    "                            \"Professional\",\n",
    "                            \"Frustrated\",\n",
    "                            \"Confused\",\n",
    "                            \"Urgent\",\n",
    "                        ],\n",
    "                        value=\"Friendly\",\n",
    "                        label=\"Customer Tone\",\n",
    "                    )\n",
    "\n",
    "                    generate_btn_batch = gr.Button(\n",
    "                        \"Generate Batch\", variant=\"primary\", size=\"lg\"\n",
    "                    )\n",
    "\n",
    "                with gr.Column(scale=2):\n",
    "                    summary_output = gr.Markdown(\n",
    "                        \"*Configure and generate a batch of conversations*\"\n",
    "                    )\n",
    "\n",
    "                    with gr.Row():\n",
    "                        json_download = gr.File(label=\"Download JSON\")\n",
    "                        csv_download = gr.File(label=\"Download CSV\")\n",
    "\n",
    "            def generate_and_save_batch_with_provider(\n",
    "                domain, issue_type, length, tone, model, ollama_model, provider, num\n",
    "            ):\n",
    "                selected_model = ollama_model if provider == \"Ollama (Local)\" else model\n",
    "                summary, json_str, csv_str = generate_batch_conversations(\n",
    "                    domain, issue_type, length, tone, selected_model, num, provider\n",
    "                )\n",
    "\n",
    "                # Save to temporary files\n",
    "                json_filename = (\n",
    "                    f\"conversations_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "                )\n",
    "                csv_filename = (\n",
    "                    f\"conversations_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "                )\n",
    "\n",
    "                with open(json_filename, \"w\") as f:\n",
    "                    f.write(json_str)\n",
    "\n",
    "                with open(csv_filename, \"w\") as f:\n",
    "                    f.write(csv_str)\n",
    "\n",
    "                return summary, json_filename, csv_filename\n",
    "\n",
    "            generate_btn_batch.click(\n",
    "                fn=generate_and_save_batch_with_provider,\n",
    "                inputs=[\n",
    "                    domain_batch,\n",
    "                    issue_type_batch,\n",
    "                    length_batch,\n",
    "                    tone_batch,\n",
    "                    model_batch,\n",
    "                    ollama_model_batch,\n",
    "                    provider_batch,\n",
    "                    num_conversations,\n",
    "                ],\n",
    "                outputs=[summary_output, json_download, csv_download],\n",
    "            )\n",
    "\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "    ### Tips:\n",
    "    - **OpenRouter:** Use cloud models (requires API key)\n",
    "    - **Ollama:** Use local models (requires Ollama running on localhost:11434)\n",
    "    - Popular Ollama models: `llama3.1`, `mistral`, `qwen2.5`, `phi3`\n",
    "    - Run `ollama list` in terminal to see your available models\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "# Launch the enhanced interface\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
